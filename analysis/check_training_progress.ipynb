{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from segmentation_failures.utils import GLOBAL_SEEDS\n",
    "from segmentation_failures.utils.io import load_expt_config\n",
    "\n",
    "expt_root = Path(\n",
    "    # \"/mnt/E132-Projekte/Projects/2023_MaxZ_segmentation_failures/cluster_logs/logs/paper_expts_2403\"\n",
    "    # \"/mnt/E132-Projekte/Projects/2023_MaxZ_segmentation_failures/cluster_logs/revision_newdataset_2407\"\n",
    "    # \"/mnt/cluster_checkpoints_ro/segfail_project/revision_architecture_2408\"\n",
    "    \"/mnt/cluster_checkpoints_ro/segfail_project/revision_newdataset_2408\"\n",
    "    # \"/mnt/E132-Projekte/Projects/2023_MaxZ_segmentation_failures/cluster_logs/revision_newdataset_2408\"\n",
    "    # \"/mnt/E132-Projekte/Projects/2023_MaxZ_segmentation_failures/cluster_logs/revision_architecture_2408/\"\n",
    ")\n",
    "# expt_root = Path(\"/mnt/cluster_checkpoints_ro/segfail_project/logs/paper_expts_2403\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_inv_mapping = {v: k for k, v in GLOBAL_SEEDS.items()}\n",
    "\n",
    "# iterate  recursively through all directories in expt_root and find\n",
    "# - train_seg directories\n",
    "# - train_image_csf directories\n",
    "# For each directory, check the seed and whether it is completed; enter this information in a dataframe\n",
    "# the resulting dataframe (one for each directory type) should have columns\n",
    "# expt_path, expt_name, dataset, seed, completed\n",
    "def check_runs(expt_group_dir, task, test_results_path=None):\n",
    "    all_results = []\n",
    "    all_configs = {}\n",
    "    for train_dir in tqdm(list(expt_group_dir.glob(f\"*/*/*/{task}\"))):\n",
    "        for expt_dir in train_dir.glob(\"*\"):\n",
    "            expt_id = expt_dir.name\n",
    "            if expt_dir.is_file():\n",
    "                continue\n",
    "            try:\n",
    "                cfg = load_expt_config(expt_dir)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Could not load config for {expt_dir}\")\n",
    "                continue\n",
    "            if \"dataset\" not in cfg:\n",
    "                dataset_id = int(cfg.datamodule.hparams.dataset_id)\n",
    "                fold = int(cfg.datamodule.hparams.fold)\n",
    "            else:\n",
    "                dataset_id = int(cfg.dataset.dataset_id)\n",
    "                fold = int(cfg.datamodule.fold)\n",
    "            # nicer expt name\n",
    "            expt_name = cfg.expt_name\n",
    "            # if \"unet_dropout\" in expt_name:\n",
    "            #     # remove everything before unet_dropout- (including)\n",
    "            #     expt_name = expt_name.split(\"unet_dropout-\")[-1]\n",
    "            #     # expt_name = map_method_names(expt_name)\n",
    "            seed = seed_inv_mapping[cfg.seed]\n",
    "            # check if completed\n",
    "            completed = (expt_dir / \"COMPLETED\").exists()\n",
    "            num_checkpoints = 0\n",
    "            ckpt_list = []\n",
    "            if (expt_dir / \"checkpoints\").exists():\n",
    "                ckpt_list =[\n",
    "                        x\n",
    "                        for x in (expt_dir / \"checkpoints\").iterdir()\n",
    "                        if x.suffix == \".ckpt\"\n",
    "                    ]\n",
    "                num_checkpoints = len(ckpt_list)\n",
    "            results_found = False\n",
    "            if test_results_path is not None:\n",
    "                results_found = (expt_dir / test_results_path).exists()\n",
    "\n",
    "            entry = {\n",
    "                # \"expt_path\": expt_dir,\n",
    "                \"expt_id\": expt_id,\n",
    "                \"expt_name\": expt_name,\n",
    "                \"dataset\": dataset_id,\n",
    "                \"seed\": seed,\n",
    "                \"fold\": fold,\n",
    "                \"completed\": completed,\n",
    "                \"num_checkpoints\": num_checkpoints,\n",
    "                \"ckpt_list\": ckpt_list,\n",
    "                \"test_results_found\": results_found,\n",
    "            }\n",
    "            all_results.append(entry)\n",
    "            all_configs[expt_id] = cfg\n",
    "\n",
    "    return pd.DataFrame(all_results), all_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation training\n",
    "train_seg_df, configs = check_runs(expt_root, \"train_seg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_df = train_seg_df.groupby(\"dataset\").get_group(515)\n",
    "# # ds_df.pivot(index=\"expt_name\", columns=\"seed\", values=\"completed\")\n",
    "# summary = (\n",
    "#     ds_df.groupby([\"expt_name\", \"fold\", \"seed\"])\n",
    "#     .agg({\"completed\": \"sum\", \"num_checkpoints\": \"sum\"})\n",
    "#     .reset_index()\n",
    "#     .pivot(index=[\"expt_name\", \"seed\"], columns=\"fold\", values=\"num_checkpoints\")\n",
    "# )\n",
    "# summary\n",
    "summary_df = (\n",
    "    train_seg_df.groupby([\"dataset\", \"expt_name\", \"fold\", \"seed\"])\n",
    "    .agg({\"completed\": \"sum\", \"num_checkpoints\": \"sum\"})\n",
    "    .reset_index()\n",
    "    .pivot(\n",
    "        index=[\"expt_name\", \"seed\"],\n",
    "        columns=[\"dataset\", \"fold\"],\n",
    "        values=\"completed\",\n",
    "    )\n",
    ")\n",
    "# summary_df.loc[:, ([514, 540, 560], slice(None))]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_seg_df.groupby([\"dataset\", \"fold\", \"seed\"]).get_group((560, 1, 1)).ckpt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSF validation\n",
    "df_csf_validate, configs = check_runs(expt_root, \"validate_pixel_csf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_df = (\n",
    "    df_csf_validate.groupby([\"dataset\", \"expt_name\", \"fold\", \"seed\"])\n",
    "    .agg({\"completed\": \"sum\", \"num_checkpoints\": \"sum\"})\n",
    "    .reset_index()\n",
    "    .pivot(\n",
    "        index=[\"expt_name\", \"seed\"],\n",
    "        columns=[\"dataset\", \"fold\"],\n",
    "        values=\"completed\",\n",
    "    )\n",
    ")\n",
    "# summary_df.loc[:, ([514, 540], slice(None))]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSF training\n",
    "df_csf_train, configs = check_runs(expt_root, \"train_image_csf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by job ID (I repeated some)\n",
    "filtered_df = df_csf_train\n",
    "# filtered_df = df_csf[\n",
    "#     df_csf.expt_name.str.contains(\"mahalanobis|-vae_\", regex=True)\n",
    "#     | (df_csf.job_id >= 23960389)\n",
    "# ]\n",
    "\n",
    "# filtered_df = df_csf[\n",
    "#     df_csf.expt_name.str.contains(\"mahalanobis|-vae_\", regex=True)\n",
    "# ]\n",
    "\n",
    "# concatenate the results for all datasets along the columns and add a multiindex with the dataset ID to the columns\n",
    "summary_df = (\n",
    "    filtered_df.groupby([\"dataset\", \"expt_name\", \"fold\"])\n",
    "    .agg({\"completed\": \"sum\", \"num_checkpoints\": \"sum\"})\n",
    "    .reset_index()\n",
    "    .pivot(index=\"expt_name\", columns=[\"dataset\", \"fold\"], values=\"completed\")\n",
    ")\n",
    "# summary_df.loc[:, ([514, 540], slice(None))]  # select all columns for dataset 500\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csf_pixel, configs = check_runs(\n",
    "    expt_root, \"test_pixel_csf\", test_results_path=\"results/metrics.npz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the results for all datasets along the columns and add a multiindex with the dataset ID to the columns\n",
    "summary_df = (\n",
    "    df_csf_pixel.groupby([\"dataset\", \"expt_name\", \"fold\"])\n",
    "    .agg({\"completed\": \"sum\", \"test_results_found\": \"sum\"})\n",
    "    .reset_index()\n",
    "    .pivot(index=\"expt_name\", columns=[\"dataset\", \"fold\"], values=\"test_results_found\")\n",
    ")\n",
    "# summary_df.loc[:, (511, slice(None))]\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csf_img, configs = check_runs(\n",
    "    expt_root, \"test_fd\", test_results_path=\"analysis/fd_metrics.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the results for all datasets along the columns and add a multiindex with the dataset ID to the columns\n",
    "summary_df = (\n",
    "    df_csf_img.groupby([\"dataset\", \"expt_name\", \"fold\"])\n",
    "    .agg({\"completed\": \"sum\", \"test_results_found\": \"sum\"})\n",
    "    .reset_index()\n",
    "    .pivot(index=\"expt_name\", columns=[\"dataset\", \"fold\"], values=\"completed\")\n",
    ")\n",
    "# summary_df.loc[:, (514, slice(None))]  # select all columns for dataset 500\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reproduce_segfail_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
